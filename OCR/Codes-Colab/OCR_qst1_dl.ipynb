{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copie de OCR.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "QiOJtCY-LVec"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import shutil\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from shutil import copyfile\n",
        "from os import getcwd\n",
        "\n",
        "#!pip install -q -U keras-tuner\n",
        "import keras_tuner as kt\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(getcwd())\n",
        "path_arab_words = f\"{getcwd()}/../AHDB.zip\"\n",
        "shutil.rmtree('/tmp')\n",
        "\n",
        "local_zip = path_arab_words\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "Q93sZLxCLoob",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fea005a9-d67a-4691-e4a8-49117dd29da5"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(os.listdir('/tmp/AHDB/AAN/')))"
      ],
      "metadata": {
        "id": "Du4-t47hLpZ_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94d5ccca-57be-4247-8693-1ec91df84af3"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "   \n",
        "    base_dir = \"/tmp/AHDB\"\n",
        "\n",
        "    train_dir = os.path.join(base_dir, 'training')\n",
        "    validation_dir = os.path.join(base_dir, 'validation')\n",
        "    testing_dir = os.path.join(base_dir, 'testing')\n",
        "    \n",
        "    s=['AAN','ABD','ALA','ALADHI','ALAM','ALLAH','ALLATI','ALYAWM','AN','AW','FI'\n",
        "    ,'HADHA','HADHIHI','HIA','HOUNAKA','HOWA','ILA','KABLA','KAD','KAMA'\n",
        "    ,'KANA','KHILALA','MA','MAA','MAN','MOHAMED','TOMA','YAKON']\n",
        "\n",
        "\n",
        "    # a loop that creates a validation and a training dir for each classe\n",
        "    # ex train_aan_dir = os.path.join(train_dir, 'AAN')\n",
        "    for k in s:\n",
        "\n",
        "      exec(f'train_{k}_dir = os.path.join(train_dir, k)')\n",
        "      exec(f'validation_{k}_dir = os.path.join(validation_dir, k)')\n",
        "      exec(f'test_{k}_dir = os.path.join(testing_dir, k)')\n",
        "      valid = '/tmp/recognize/validation/'+k+'/'\n",
        "      train ='/tmp/recognize/training/'+k+'/'\n",
        "      test ='/tmp/recognize/testing/'+k+'/'\n",
        "      os.makedirs(test)\n",
        "      os.makedirs(train)\n",
        "      os.makedirs(valid)\n",
        "     \n",
        "\n",
        "\n",
        "except OSError:\n",
        "    pass"
      ],
      "metadata": {
        "id": "Ekt4zbemLr9j"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_data(SOURCE, TRAINING,VALIDATION, TESTING, TRAIN_SIZE, VAL_SIZE):\n",
        "\n",
        "    listdir= os.listdir (SOURCE)\n",
        "    list_source= random.sample(listdir,len(listdir))\n",
        "    for i in range (len (list_source)):\n",
        "        file_source = os.path.join(SOURCE,list_source[i-1])\n",
        "        file_trainin = os.path.join(TRAINING,list_source[i-1])\n",
        "        file_valid = os.path.join(VALIDATION,list_source[i-1])\n",
        "        file_tastin = os.path.join(TESTING,list_source[i-1])\n",
        "        if (i<len (list_source)*TRAIN_SIZE):\n",
        "            if (os.path.getsize(file_source))!=0:\n",
        "                #copy it\n",
        "                copyfile(file_source,file_trainin)\n",
        "        elif i>= len (list_source)*TRAIN_SIZE and i <len (list_source)*VAL_SIZE :\n",
        "             if (os.path.getsize(file_source))!=0:\n",
        "                #copy it\n",
        "                copyfile(file_source,file_valid)\n",
        "        else :\n",
        "          if (os.path.getsize(file_source))!=0:\n",
        "                #copy it\n",
        "                copyfile(file_source,file_tastin)\n",
        "\n",
        "\n",
        "train_size = .60  # 90% training and the others for test \n",
        "valid_size = .80  \n",
        "    \n",
        "    \n",
        "for k in s:\n",
        "      source_dir=\"/tmp/AHDB/\"+k+\"/\"\n",
        "      testing_dir = '/tmp/recognize/testing/'+k+'/'\n",
        "      train_dir ='/tmp/recognize/training/'+k+'/'\n",
        "      validation_dir ='/tmp/recognize/validation/'+k+'/'\n",
        "      split_data(source_dir, train_dir,validation_dir, testing_dir, train_size,valid_size)\n"
      ],
      "metadata": {
        "id": "tpFwBvM7LvYi"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DEFINE A KERAS MODEL TO CLASSIFY THE 28 CLASSES\n",
        "# USING 3 CONVOLUTION LAYERS\n",
        "\n",
        "\n",
        "#_______________tweeking parameters____________\n",
        "# Tune the number of units in the first Dense layer\n",
        "# Choose an optimal value between 32-512\n",
        "\n",
        "def model_builder(hp):\n",
        "    \n",
        "  hp_units = hp.Int('units', min_value=32, max_value=512, step=32)\n",
        "  hp_activation=hp.Choice('activation',values=[\"relu\",\"elu\"])\n",
        "  model = tf.keras.models.Sequential([\n",
        "\n",
        "      # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n",
        "      tf.keras.layers.Conv2D(16, (3,3), activation=hp_activation, input_shape=(150, 150, 3)),\n",
        "      tf.keras.layers.MaxPooling2D(2,2),\n",
        "      tf.keras.layers.Conv2D(32, (3,3), activation=hp_activation),\n",
        "      tf.keras.layers.MaxPooling2D(2,2), \n",
        "      tf.keras.layers.Conv2D(64, (3,3), activation=hp_activation), \n",
        "      tf.keras.layers.MaxPooling2D(2,2),\n",
        "      tf.keras.layers.Conv2D(128, (3,3), activation=hp_activation), \n",
        "      tf.keras.layers.MaxPooling2D(2,2),\n",
        "      # Flatten the results to feed into a DNN\n",
        "      tf.keras.layers.Flatten(), \n",
        "      #  hidden layer\n",
        "      tf.keras.layers.Dense(hp_units, activation=hp_activation), \n",
        "      # Only 1 output neuron. It will contain a value from 0 or 1 where 1 in the indice of the predicted class\n",
        "      tf.keras.layers.Dense(28, activation='softmax') \n",
        "  ])\n",
        "\n",
        "  # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
        "  hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "  model.compile(optimizer=RMSprop(lr=hp_learning_rate), loss='categorical_crossentropy', metrics=['acc'])\n",
        "\n",
        "  return model\n",
        "\n",
        "\n",
        "\n",
        " "
      ],
      "metadata": {
        "id": "pZIeLewJL6tL"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TRAINING_DIR = '/tmp/recognize/training/'\n",
        "train_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
        "train_generator =train_datagen.flow_from_directory(TRAINING_DIR,\n",
        "                                                   batch_size=10,\n",
        "                                                    class_mode='categorical',\n",
        "                                                    target_size=(150, 150))  \n",
        "\n",
        "\n",
        "VALIDATION_DIR ='/tmp/recognize/validation/' \n",
        "validation_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
        "validation_generator = validation_datagen.flow_from_directory(VALIDATION_DIR,\n",
        "                                                         batch_size=10,\n",
        "                                                         class_mode  = 'categorical',\n",
        "                                                         target_size = (150, 150))\n",
        "\n",
        "\n",
        "\n",
        "TESTING_DIR ='/tmp/recognize/testing/' \n",
        "testing_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
        "testing_generator = validation_datagen.flow_from_directory(TESTING_DIR,\n",
        "                                                         batch_size=10,\n",
        "                                                         class_mode  = 'categorical',\n",
        "                                                         target_size = (150, 150))\n",
        "                       \n",
        "\n",
        "\n",
        "''' training_datagen = ImageDataGenerator(\n",
        "      rescale = 1./255,\n",
        "\t    rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      #horizontal_flip=True,\n",
        "      brightness_range=[0.4,1.5],\n",
        "      fill_mode='nearest')\n",
        "validation_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "train_generator = training_datagen.flow_from_directory(\n",
        "\tTRAINING_DIR,\n",
        "\ttarget_size=(150,150),\n",
        "\tclass_mode='categorical',\n",
        "  batch_size=10\n",
        ")\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "\tVALIDATION_DIR,\n",
        "\ttarget_size=(150,150),\n",
        "\tclass_mode='categorical',\n",
        "  batch_size=10\n",
        ") '''\n",
        "\n",
        "# Expected Output:\n",
        "# Found 2700 images belonging to 2 classes.\n",
        "# Found 300 images belonging to 2 classes.\n"
      ],
      "metadata": {
        "id": "bYvpAN_xL-6k",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "outputId": "9ae99816-0296-4697-90ea-49aa24261204"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 581 images belonging to 28 classes.\n",
            "Found 195 images belonging to 28 classes.\n",
            "Found 180 images belonging to 28 classes.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\" training_datagen = ImageDataGenerator(\\n      rescale = 1./255,\\n\\t    rotation_range=40,\\n      width_shift_range=0.2,\\n      height_shift_range=0.2,\\n      shear_range=0.2,\\n      zoom_range=0.2,\\n      #horizontal_flip=True,\\n      brightness_range=[0.4,1.5],\\n      fill_mode='nearest')\\nvalidation_datagen = ImageDataGenerator(rescale = 1./255)\\n\\ntrain_generator = training_datagen.flow_from_directory(\\n\\tTRAINING_DIR,\\n\\ttarget_size=(150,150),\\n\\tclass_mode='categorical',\\n  batch_size=10\\n)\\n\\nvalidation_generator = validation_datagen.flow_from_directory(\\n\\tVALIDATION_DIR,\\n\\ttarget_size=(150,150),\\n\\tclass_mode='categorical',\\n  batch_size=10\\n) \""
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuner = kt.Hyperband(model_builder,\n",
        "                     objective='val_acc',\n",
        "                     max_epochs=15,\n",
        "                     factor=3,\n",
        "                      overwrite=True\n",
        "                     #directory='my_dir',\n",
        "                     #project_name='intro_to_kt'\n",
        "                     )\n",
        "\n",
        "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
        "\n",
        "tuner.search(train_generator, epochs=50,validation_data=validation_generator, callbacks=[stop_early])\n",
        "\n",
        "# Get the optimal hyperparameters\n",
        "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "print(f\"\"\"\n",
        "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
        "layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
        "is {best_hps.get('learning_rate')}.\n",
        "\"\"\")\n",
        "''' \n",
        "history = model.fit_generator(train_generator,\n",
        "                              epochs=10,\n",
        "                              verbose=1,\n",
        "                              validation_data=validation_generator) '''\n",
        "# 1h 20 min"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "RTm1dpoTL_gD",
        "outputId": "751144a2-33d3-4ac0-bbed-7c27a720682c"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 30 Complete [00h 02m 44s]\n",
            "val_acc: 0.03589743748307228\n",
            "\n",
            "Best val_acc So Far: 0.764102578163147\n",
            "Total elapsed time: 00h 43m 16s\n",
            "INFO:tensorflow:Oracle triggered exit\n",
            "\n",
            "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
            "layer is 224 and the optimal learning rate for the optimizer\n",
            "is 0.001.\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' \\nhistory = model.fit_generator(train_generator,\\n                              epochs=10,\\n                              verbose=1,\\n                              validation_data=validation_generator) '"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model with the optimal hyperparameters and train it on the data for 50 epochs\n",
        "model = tuner.hypermodel.build(best_hps)\n",
        "history = model.fit(train_generator, epochs=50,validation_data=validation_generator)\n",
        "\n",
        "val_acc_per_epoch = history.history['val_acc']\n",
        "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
        "print('Best epoch: %d' % (best_epoch,))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ebB5w-KtvXZj",
        "outputId": "e4149573-3665-4ab7-ba11-7efe322eb9c3"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "59/59 [==============================] - 17s 278ms/step - loss: 3.3936 - acc: 0.0585 - val_loss: 3.1367 - val_acc: 0.1897\n",
            "Epoch 2/50\n",
            "59/59 [==============================] - 16s 269ms/step - loss: 2.1871 - acc: 0.3873 - val_loss: 1.3692 - val_acc: 0.6154\n",
            "Epoch 3/50\n",
            "59/59 [==============================] - 16s 272ms/step - loss: 0.8017 - acc: 0.7780 - val_loss: 1.2522 - val_acc: 0.6308\n",
            "Epoch 4/50\n",
            "59/59 [==============================] - 16s 271ms/step - loss: 0.2968 - acc: 0.9105 - val_loss: 1.0499 - val_acc: 0.6923\n",
            "Epoch 5/50\n",
            "59/59 [==============================] - 16s 269ms/step - loss: 0.1075 - acc: 0.9725 - val_loss: 1.3697 - val_acc: 0.7385\n",
            "Epoch 6/50\n",
            "59/59 [==============================] - 16s 270ms/step - loss: 0.0704 - acc: 0.9776 - val_loss: 1.1104 - val_acc: 0.7641\n",
            "Epoch 7/50\n",
            "59/59 [==============================] - 16s 267ms/step - loss: 0.0576 - acc: 0.9845 - val_loss: 1.4797 - val_acc: 0.7436\n",
            "Epoch 8/50\n",
            "59/59 [==============================] - 16s 272ms/step - loss: 0.0091 - acc: 0.9983 - val_loss: 1.5889 - val_acc: 0.7179\n",
            "Epoch 9/50\n",
            "59/59 [==============================] - 16s 270ms/step - loss: 0.0409 - acc: 0.9845 - val_loss: 1.3664 - val_acc: 0.7487\n",
            "Epoch 10/50\n",
            "59/59 [==============================] - 16s 273ms/step - loss: 1.0334e-04 - acc: 1.0000 - val_loss: 1.3927 - val_acc: 0.7538\n",
            "Epoch 11/50\n",
            "59/59 [==============================] - 16s 273ms/step - loss: 2.1005e-06 - acc: 1.0000 - val_loss: 1.5419 - val_acc: 0.7744\n",
            "Epoch 12/50\n",
            "59/59 [==============================] - 16s 271ms/step - loss: 1.0526e-07 - acc: 1.0000 - val_loss: 1.7131 - val_acc: 0.7692\n",
            "Epoch 13/50\n",
            "59/59 [==============================] - 16s 270ms/step - loss: 4.7191e-09 - acc: 1.0000 - val_loss: 1.7878 - val_acc: 0.7795\n",
            "Epoch 14/50\n",
            "59/59 [==============================] - 16s 269ms/step - loss: 2.0518e-10 - acc: 1.0000 - val_loss: 1.7501 - val_acc: 0.7795\n",
            "Epoch 15/50\n",
            "59/59 [==============================] - 16s 270ms/step - loss: 4.1036e-10 - acc: 1.0000 - val_loss: 1.7811 - val_acc: 0.7744\n",
            "Epoch 16/50\n",
            "59/59 [==============================] - 16s 269ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.7653 - val_acc: 0.7795\n",
            "Epoch 17/50\n",
            "59/59 [==============================] - 16s 275ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.7784 - val_acc: 0.7795\n",
            "Epoch 18/50\n",
            "59/59 [==============================] - 16s 270ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.7954 - val_acc: 0.7795\n",
            "Epoch 19/50\n",
            "59/59 [==============================] - 16s 271ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.8154 - val_acc: 0.7795\n",
            "Epoch 20/50\n",
            "59/59 [==============================] - 16s 275ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.8336 - val_acc: 0.7846\n",
            "Epoch 21/50\n",
            "25/59 [===========>..................] - ETA: 8s - loss: 0.0000e+00 - acc: 1.0000"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-287eb3914985>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Build the model with the optimal hyperparameters and train it on the data for 50 epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_hps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mval_acc_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 _r=1):\n\u001b[1;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3130\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3131\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3133\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1959\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1960\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1962\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    601\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    604\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 59\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(best_hps.get('activation'))\n",
        "hypermodel = tuner.hypermodel.build(best_hps)\n",
        "\n",
        "# Retrain the model\n",
        "hyperhistory=hypermodel.fit(train_generator, epochs=best_epoch,validation_data=validation_generator)"
      ],
      "metadata": {
        "id": "XK-o-85nxsRv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PLOT LOSS AND ACCURACY\n",
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.image  as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#-----------------------------------------------------------\n",
        "# Retrieve a list of list results on training and test data\n",
        "# sets for each training epoch\n",
        "#-----------------------------------------------------------\n",
        "acc=hyperhistory.history['acc']\n",
        "val_acc=hyperhistory.history['val_acc']\n",
        "loss=hyperhistory.history['loss']\n",
        "val_loss=hyperhistory.history['val_loss']\n",
        "\n",
        "epochs=range(len(acc)) # Get number of epochs\n",
        "\n",
        "#------------------------------------------------\n",
        "# Plot training and validation accuracy per epoch\n",
        "#------------------------------------------------\n",
        "plt.plot(epochs, acc, 'r', \"Training Accuracy\")\n",
        "plt.plot(epochs, val_acc, 'b', \"Validation Accuracy\")\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.figure()\n",
        "\n",
        "#------------------------------------------------\n",
        "# Plot training and validation loss per epoch\n",
        "#------------------------------------------------\n",
        "plt.plot(epochs, loss, 'r', \"Training Loss\")\n",
        "plt.plot(epochs, val_loss, 'b', \"Validation Loss\")\n",
        "\n",
        "\n",
        "plt.title('Training and validation loss')\n",
        "\n",
        "\n",
        "# Desired output. Charts with training and validation metrics. No crash :)"
      ],
      "metadata": {
        "id": "HCcplv0GMCB6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluate the model with test data\n",
        "\n",
        "#get the labels\n",
        "x_test,y_test=testing_generator.next()\n",
        "eval_result = hypermodel.evaluate(x_test, y_test)\n",
        "print(\"[test loss, test accuracy]:\", eval_result)\n",
        "\n"
      ],
      "metadata": {
        "id": "pmvqwvfnyfNT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from google.colab import files\n",
        "from keras.preprocessing import image\n",
        "\n",
        "\n",
        "\n",
        "!mkdir -p \"/content/saved_model\"\n",
        "hypermodel.save('/content/saved_model/my_model_2') \n",
        "!zip -r '/content/saved_model/file_no_2.zip' '/content/saved_model/my_model_2'\n",
        "from google.colab import files\n",
        "#files.download(\"/content/saved_model/file_no.zip\")\n",
        "\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        " \n",
        "  # predicting images\n",
        "  path = '/content/' + fn\n",
        "  img = image.load_img(path, target_size=(150, 150))\n",
        "  x = image.img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "\n",
        "  images = np.vstack([x])\n",
        "  classes = hypermodel.predict(images, batch_size=10)\n",
        "  print(\"---------------Found classes ----------------\")\n",
        "  print( classes[0])\n",
        "  print( classes[0][0])\n",
        "  for i in range (len(classes[0])):\n",
        "    if (1-classes[0][i])<0.1:\n",
        "      print(s[i])"
      ],
      "metadata": {
        "id": "oyGBJ08bdHRV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}